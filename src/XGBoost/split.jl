
function getweight(gradient::LossGradient, Î»::Real) 
    -gradient.âˆ‚ğ‘™ / (gradient.âˆ‚Â²ğ‘™ + Î»)
end

function getloss(âˆ‚ğ‘™::Real, âˆ‚Â²ğ‘™::Real, Î»::Real, Î³::Real)
    -0.5 * âˆ‚ğ‘™ * âˆ‚ğ‘™ / (âˆ‚Â²ğ‘™ + Î») + Î³
end

function getloss(node::LeafNode, Î»::Real, Î³::Real)
    âˆ‚ğ‘™ = node.gradient.âˆ‚ğ‘™
    âˆ‚Â²ğ‘™ = node.gradient.âˆ‚Â²ğ‘™
    getloss(âˆ‚ğ‘™, âˆ‚Â²ğ‘™, Î», Î³)
end

function getloss(node::SplitNode, Î»::Real, Î³::Real)
    node.loss
end

function sumgradient(nodeids::Vector{<:Integer}, nodecansplit::Vector{Bool}, factor::AbstractFactor, partitions::Vector{LevelPartition},
                     âˆ‚ğ‘™covariate::AbstractCovariate, âˆ‚Â²ğ‘™covariate::AbstractCovariate, slicelength::Integer)
    
    nodecount = length(nodecansplit)
    levelcounts = [p.inclmissing ? length(p.mask) + 1 : length(p.mask) for p in partitions]
    inclmiss = [p.inclmissing for p in partitions]
    âˆ‚ğ‘™sum0 = [(nodecansplit[node] ? [0.0 for i in 1:(levelcounts[node])] : Vector{Float64}()) for node in 1:nodecount]
    âˆ‚Â²ğ‘™sum0 = [(nodecansplit[node] ? [0.0 for i in 1:(levelcounts[node])] : Vector{Float64}()) for node in 1:nodecount]

    fromobs = 1
    toobs = length(nodeids)
    nodeslices = slice(nodeids, fromobs, toobs, slicelength)
    factorslices = slice(factor, fromobs, toobs, slicelength)
    âˆ‚ğ‘™slices = slice(âˆ‚ğ‘™covariate, fromobs, toobs, slicelength)
    âˆ‚Â²ğ‘™slices = slice(âˆ‚Â²ğ‘™covariate, fromobs, toobs, slicelength)
    zipslices = zip4(nodeslices, factorslices, âˆ‚ğ‘™slices, âˆ‚Â²ğ‘™slices)
    fold((âˆ‚ğ‘™sum0, âˆ‚Â²ğ‘™sum0), zipslices) do gradsum, zipslice
        nodeslice, factorslice, âˆ‚ğ‘™slice, âˆ‚Â²ğ‘™slice = zipslice
        âˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum = gradsum
        for i in 1:length(nodeslice)
            nodeid = nodeslice[i]
            if nodecansplit[nodeid]
                levelindex = factorslice[i]
                if levelindex == 0
                    âˆ‚ğ‘™sum[nodeid][1] += âˆ‚ğ‘™slice[i]
                    âˆ‚Â²ğ‘™sum[nodeid][1] += âˆ‚Â²ğ‘™slice[i]
                elseif inclmiss[nodeid]
                    âˆ‚ğ‘™sum[nodeid][levelindex + 1] += âˆ‚ğ‘™slice[i]
                    âˆ‚Â²ğ‘™sum[nodeid][levelindex + 1] += âˆ‚Â²ğ‘™slice[i]
                else
                    âˆ‚ğ‘™sum[nodeid][levelindex] += âˆ‚ğ‘™slice[i]
                    âˆ‚Â²ğ‘™sum[nodeid][levelindex] += âˆ‚Â²ğ‘™slice[i]
                end
            end
        end
        (âˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum)
    end
    [(nodecansplit[node] ? [LossGradient(âˆ‚ğ‘™sum0[node][i], âˆ‚Â²ğ‘™sum0[node][i]) for i in 1:(levelcounts[node])] : Vector{LossGradient}()) for node in 1:nodecount]
end

function splitnodeids!(nodeids::Vector{<:Integer}, layer::TreeLayer, slicelength::Integer)
    nodes = layer.nodes
    nodecount = length(nodes)
    len = length(nodeids)
    issplitnode = [isa(n, SplitNode) for n in nodes]
    intercept = ConstFactor(len)
    factors = widenfactors([isa(n, LeafNode) ? intercept : n.factor for n in nodes])
    leftpartitions = [isa(n, SplitNode) ? n.leftpartition : LevelPartition(Vector{Bool}(), false)  for n in nodes]
    factorslices = zipn([slice(factor, 1, len, slicelength) for factor in factors])
    nodeslices = slice(nodeids, 1, len, slicelength)
    foreach(zip2(nodeslices, factorslices)) do x
        nodeslice, fslices = x
        for (i, nodeid) in enumerate(nodeslice)
            if nodeid > 0
                if issplitnode[nodeid]
                    levelindex = fslices[nodeid][i]
                    leftpartition = leftpartitions[nodeid]
                    misswithleft = leftpartition.inclmissing
                    if levelindex > length(leftpartition.mask)
                        nodeslice[i] = 0
                    else
                        nodeslice[i] = (levelindex == 0 && misswithleft) || leftpartition.mask[levelindex] ? (2 * nodeslice[i] - 1) : (2 * nodeslice[i]) 
                    end
                else
                    nodeslice[i] = 2 * nodeslice[i] - 1
                end
            end
        end
    end
    nodeids
end

function getsplitnode(factor::AbstractFactor, partition::LevelPartition, gradient::Vector{LossGradient},
                      Î»::Real, Î³::Real, minâˆ‚Â²ğ‘™::Real)

    inclmiss = partition.inclmissing
    gradstart = inclmiss ? 2 : 1
    âˆ‚ğ‘™sum0 = sum((grad -> grad.âˆ‚ğ‘™), gradient[gradstart:end])
    âˆ‚Â²ğ‘™sum0 = sum((grad -> grad.âˆ‚Â²ğ‘™), gradient[gradstart:end]) 
    missâˆ‚ğ‘™ = inclmiss ? gradient[1].âˆ‚ğ‘™ : 0.0
    missâˆ‚Â²ğ‘™ = inclmiss ? gradient[1].âˆ‚Â²ğ‘™ : 0.0
    bestloss = getloss(âˆ‚ğ‘™sum0 + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 + missâˆ‚Â²ğ‘™, Î», Î³)
    levelcount = length(partition.mask)
    split = SplitNode(factor, partition, LevelPartition(zeros(Bool, levelcount), false),
                      LossGradient(âˆ‚ğ‘™sum0 + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 + missâˆ‚Â²ğ‘™), LossGradient(0.0, 0.0),
                      bestloss)
    
    leftâˆ‚ğ‘™sum = gradient[gradstart].âˆ‚ğ‘™
    leftâˆ‚Â²ğ‘™sum = gradient[gradstart].âˆ‚Â²ğ‘™

    firstlevelwithmiss = getloss(leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum, Î», Î³)
    firstlevelwitouthmiss = getloss(leftâˆ‚ğ‘™sum, leftâˆ‚Â²ğ‘™sum, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™, Î», Î³)

    if firstlevelwithmiss < bestloss && (leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum >= minâˆ‚Â²ğ‘™)
        if firstlevelwitouthmiss < firstlevelwithmiss && (leftâˆ‚Â²ğ‘™sum >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™)
            split.leftgradient = LossGradient(leftâˆ‚ğ‘™sum, leftâˆ‚Â²ğ‘™sum)
            split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™)
            split.leftpartition = LevelPartition([j == 1 for j in 1:levelcount], false)
            split.rightpartition = LevelPartition([j == 1 ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
            split.loss = firstlevelwitouthmiss
        else
            split.leftgradient = LossGradient(leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™)
            split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum)
            split.leftpartition = LevelPartition([j == 1 for j in 1:levelcount], partition.inclmissing)
            split.rightpartition = LevelPartition([j == 1 ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
            split.loss = firstlevelwithmiss
        end
    end

    for i in 2:(levelcount - 1)
        if !partition.mask[i]
            continue
        end
        âˆ‚ğ‘™ = gradient[i + gradstart - 1].âˆ‚ğ‘™
        âˆ‚Â²ğ‘™ = gradient[i + gradstart - 1].âˆ‚Â²ğ‘™

        singlelevelwithmisstotal = getloss(âˆ‚ğ‘™ + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - âˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™, Î», Î³)
        singlelevelwitouthmisstotal = getloss(âˆ‚ğ‘™, âˆ‚Â²ğ‘™, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - âˆ‚ğ‘™ + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™, Î», Î³)

        leftâˆ‚ğ‘™sum += âˆ‚ğ‘™
        leftâˆ‚Â²ğ‘™sum += âˆ‚Â²ğ‘™

        leftwithmisstotal = getloss(leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum, Î», Î³)
        leftwithoutmisstotal = getloss(leftâˆ‚ğ‘™sum, leftâˆ‚Â²ğ‘™sum, Î», Î³) + getloss(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™, Î», Î³)

        if singlelevelwithmisstotal < split.loss && (âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™)
            if singlelevelwitouthmisstotal < singlelevelwithmisstotal && (âˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™)
                split.leftgradient = LossGradient(âˆ‚ğ‘™, âˆ‚Â²ğ‘™)
                split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - âˆ‚ğ‘™ + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™)
                split.leftpartition = LevelPartition([j == i for j in 1:levelcount], false)
                split.rightpartition = LevelPartition([j == i ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
                split.loss = singlelevelwitouthmisstotal
            else
                split.leftgradient = LossGradient(âˆ‚ğ‘™ + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™ + missâˆ‚Â²ğ‘™)
                split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - âˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - âˆ‚Â²ğ‘™)
                split.leftpartition = LevelPartition([j == i for j in 1:levelcount], partition.inclmissing)
                split.rightpartition = LevelPartition([j == i ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
                split.loss = singlelevelwithmisstotal
            end
        end

        if leftwithmisstotal < split.loss && (leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum >= minâˆ‚Â²ğ‘™)
            if leftwithoutmisstotal < leftwithmisstotal && (leftâˆ‚Â²ğ‘™sum >= minâˆ‚Â²ğ‘™) && (âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™ >= minâˆ‚Â²ğ‘™)
                split.leftgradient = LossGradient(leftâˆ‚ğ‘™sum, leftâˆ‚Â²ğ‘™sum)
                split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™)
                split.leftpartition = LevelPartition([(j <= i) ? partition.mask[j] : false for j in 1:levelcount], false)
                split.rightpartition = LevelPartition([j <= i ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
                split.loss = leftwithoutmisstotal
            else
                split.leftgradient = LossGradient(leftâˆ‚ğ‘™sum + missâˆ‚ğ‘™, leftâˆ‚Â²ğ‘™sum + missâˆ‚Â²ğ‘™)
                split.rightgradient = LossGradient(âˆ‚ğ‘™sum0 - leftâˆ‚ğ‘™sum, âˆ‚Â²ğ‘™sum0 - leftâˆ‚Â²ğ‘™sum)
                split.leftpartition = LevelPartition([(j <= i) ? partition.mask[j] : false for j in 1:levelcount], partition.inclmissing)
                split.rightpartition = LevelPartition([j <= i ? false : partition.mask[j] for j in 1:levelcount], partition.inclmissing)
                split.loss = leftwithmisstotal
            end
        end
    end
    if count(split.rightpartition.mask) > 0
        Nullable{SplitNode}(split)
    else
        Nullable{SplitNode}()
    end
end

function findbestsplit(nodeids::Vector{<:Integer}, nodes::Vector{TreeNode}, factors::Vector{<:AbstractFactor},
                       âˆ‚ğ‘™covariate::AbstractCovariate, âˆ‚Â²ğ‘™covariate::AbstractCovariate,
                       Î»::Real, Î³::Real, minâˆ‚Â²ğ‘™::Real, slicelength::Integer)

    foldl(nodes, enumerate(factors)) do currsplit, nfactor
        n, factor = nfactor
        partitions = [node.partitions[factor] for node in nodes]
        nodecansplit = [n.cansplit for n in nodes]
        gradient = sumgradient(nodeids, nodecansplit, factor, partitions, âˆ‚ğ‘™covariate, âˆ‚Â²ğ‘™covariate, slicelength)
        newsplit = map(enumerate(gradient)) do x
            i, grad = x
            if nodes[i].cansplit
                partition = nodes[i].partitions[factor]
                if count(partition.mask) > 1
                    getsplitnode(factor, nodes[i].partitions[factor],  grad, Î», Î³, minâˆ‚Â²ğ‘™)
                else
                    Nullable{SplitNode}()
                end
            else
                Nullable{SplitNode}()
            end
        end
        res = Vector{TreeNode}(length(newsplit))
        for i in 1:length(newsplit)
             if !isnull(newsplit[i]) && get(newsplit[i]).loss < getloss(currsplit[i], Î», Î³) 
                res[i] = get(newsplit[i])  
             else
                res[i] = currsplit[i] 
             end
        end
        res
    end
end

function updatestate(state::TreeGrowState, layer::TreeLayer)
    splitnodeids!(state.nodeids, layer, state.slicelength)  
    factors = state.factors
    newnodes = Vector{LeafNode}(2 * length(state.nodes))
    for (i, n) in enumerate(layer.nodes)
        if isa(n, SplitNode)
            leftpartitions = map(state.nodes[i].partitions) do x
                f, p = x
                if f == n.factor
                    f => n.leftpartition
                else
                    x
                end
            end
            rightpartitions = map(state.nodes[i].partitions) do x
                f, p = x
                if f == n.factor
                    f => n.rightpartition
                else
                    x
                end
            end
            newnodes[2 * i - 1] = LeafNode(n.leftgradient,
                                           n.leftgradient.âˆ‚Â²ğ‘™ >= state.minâˆ‚Â²ğ‘™,
                                           leftpartitions)
            newnodes[2 * i] = LeafNode(n.rightgradient,
                                       n.rightgradient.âˆ‚Â²ğ‘™ >= state.minâˆ‚Â²ğ‘™,
                                       rightpartitions)
        else
            newnodes[2 * i - 1] = LeafNode(n.gradient, false, n.partitions)
            newnodes[2 * i] = LeafNode(n.gradient, false, n.partitions)
        end
    end
    activefactors = filter(factors) do f
        any(map((n -> count(n.partitions[f].mask) > 1), newnodes))
    end 
    state.factors = activefactors
    for n in newnodes
        n.partitions = filter(n.partitions) do f, p
            f in activefactors
        end
    end
    state.nodes = newnodes
    state
end

function nextlayer(state::TreeGrowState)
    layernodes = findbestsplit(state.nodeids, state.nodes, state.factors,
                               state.âˆ‚ğ‘™covariate, state.âˆ‚Â²ğ‘™covariate, state.Î»,
                               state.Î³, state.minâˆ‚Â²ğ‘™, state.slicelength)
    layer = TreeLayer(layernodes)
    updatestate(state, layer)
    Nullable{TreeLayer}(layer), state      
end

function predict(treelayer::TreeLayer, nodeids::Vector{<:Integer}, Î»)
    weights = Vector{Float64}(2 * length(treelayer.nodes))
    for (i, node) in enumerate(treelayer.nodes)
        if isa(node, SplitNode)
            weights[2 * i - 1] = getweight(node.leftgradient, Î»)
            weights[2 * i] = getweight(node.rightgradient, Î»)
        else
            weights[2 * i - 1] = getweight(node.gradient, Î»)
            weights[2 * i] = getweight(node.gradient, Î»)
        end
    end
    (nodeid -> nodeid > 0 ? weights[nodeid] : NaN64).(nodeids)
end

function predict(tree::Tree, dataframe::AbstractDataFrame)
    len = length(dataframe)
    maxnodecount = 2 ^ tree.maxdepth
    nodeids = maxnodecount <= typemax(UInt8) ? ones(UInt8, len) : (maxnodecount <= typemax(UInt16) ? ones(UInt16, len) : ones(UInt32, len))
    nodes = Vector{TreeNode}()
    for layer in tree.layers
        nodes = [isa(n, SplitNode) ? SplitNode(map(n.factor, dataframe), n.leftpartition, n.rightpartition, n.leftgradient, n.rightgradient, n.loss) : n for n in layer.nodes]
        splitnodeids!(nodeids, TreeLayer(nodes), tree.slicelength)
    end
    predict(TreeLayer(nodes), nodeids, tree.Î»)
end

function growtree(factors::Vector{<:AbstractFactor}, âˆ‚ğ‘™covariate::AbstractCovariate,
                  âˆ‚Â²ğ‘™covariate::AbstractCovariate, maxdepth::Integer, Î»::Real, Î³::Real,
                  minâˆ‚Â²ğ‘™::Real, slicelength::Integer)

    len = length(âˆ‚ğ‘™covariate)
    maxnodecount = 2 ^ maxdepth
    nodeids = maxnodecount <= typemax(UInt8) ? ones(UInt8, len) : (maxnodecount <= typemax(UInt16) ? ones(UInt16, len) : ones(UInt32, len))
    intercept = ConstFactor(len)
    grad0 = sumgradient(nodeids, [true], intercept, [LevelPartition([true], false)], âˆ‚ğ‘™covariate, âˆ‚Â²ğ‘™covariate, slicelength)[1][1]
    nodes0 = Vector{TreeNode}()
    push!(nodes0, LeafNode(grad0, true, Dict([f => LevelPartition(ones(Bool, length(getlevels(f))), true) for f in factors])))
    state0 = TreeGrowState(nodeids, nodes0, factors, âˆ‚ğ‘™covariate, âˆ‚Â²ğ‘™covariate, Î», Î³, minâˆ‚Â²ğ‘™, slicelength)
    layers = collect(Iterators.take(Seq(TreeLayer, state0, nextlayer), maxdepth))
    tree = Tree(layers, Î», Î³, minâˆ‚Â²ğ‘™, maxdepth, slicelength)
    pred = predict(tree.layers[end], nodeids, Î»)
    tree, pred
end

